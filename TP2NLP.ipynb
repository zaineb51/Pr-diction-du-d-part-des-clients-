{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPzTt3xZJ/AzElzZOhHlP/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zaineb51/Pr-diction-du-d-part-des-clients-/blob/main/TP2NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3m1H8HjQzhc",
        "outputId": "916a8c54-1f1e-4718-cebb-e85852a5e9d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#importez les bibliothèques\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# charger le fichier csv\n",
        "data_path = \"/content/sample_data/departements-region.csv\"\n",
        "df =pd.read_csv(data_path)\n",
        "\n",
        "# afficher les données\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ9KSqFOeEIB",
        "outputId": "93a35fa2-b28f-4d67-f569-2e35ccf579eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  num_dep                 dep_name                 region_name\n",
            "0      01                      Ain        Auvergne-Rhône-Alpes\n",
            "1      02                    Aisne             Hauts-de-France\n",
            "2      03                   Allier        Auvergne-Rhône-Alpes\n",
            "3      04  Alpes-de-Haute-Provence  Provence-Alpes-Côte d'Azur\n",
            "4      05             Hautes-Alpes  Provence-Alpes-Côte d'Azur\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convertir les données en minuscules:\n",
        "df=df.apply(lambda x: x.astype(str).str.lower())"
      ],
      "metadata": {
        "id": "hiRhZGHXtgaP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#supprimer la ponctuation\n",
        "df = df.apply(lambda x: x.str.translate(str.maketrans('', '', string.punctuation)))"
      ],
      "metadata": {
        "id": "Ua4cF65O8Iac"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#appliquer la tokenization:\n",
        "df = df.apply(lambda x: x.apply(nltk.word_tokenize))"
      ],
      "metadata": {
        "id": "ZIUGfsvM-RN5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#suppprimer les mots vides (stop words)\n",
        "stop_words = set(stopwords.words('french'))\n",
        "df = df.apply(lambda x: x.apply(lambda word: ' '.join(word).split()))\n",
        "df = df.apply(lambda x: x.apply(lambda word: ' '.join([w for w in word if w not in stop_words])))"
      ],
      "metadata": {
        "id": "7L2SEv4CAvZM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#appliquer la lemmatisation des mots :\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df = df.apply(lambda x: x.apply(lambda word: ' '.join([lemmatizer.lemmatize(w) for w in word.split()])))"
      ],
      "metadata": {
        "id": "Wn7XrN-6C96V"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#afficher les donnèes appprès traitement :\n",
        "print(\"\\nDonnées après traitement :\\n\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9vVhOBdDTao",
        "outputId": "0275beaa-fa91-46c5-bd7c-fe7e763878c0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Données après traitement :\n",
            "\n",
            "  num_dep              dep_name              region_name\n",
            "0      01                   ain       auvergnerhônealpes\n",
            "1      02                 aisne            hautsdefrance\n",
            "2      03                allier       auvergnerhônealpes\n",
            "3      04  alpesdehauteprovence  provencealpescôte dazur\n",
            "4      05           hautesalpes  provencealpescôte dazur\n"
          ]
        }
      ]
    }
  ]
}